{"cells":[{"cell_type":"markdown","id":"862bb3d0-d582-4e44-a9be-25b7c31603ab","metadata":{"id":"862bb3d0-d582-4e44-a9be-25b7c31603ab"},"source":["# *Week 1, Exercise 1: Introduction to Segmentation*\n"," \n","## YOU HAVE TO HAND IN ON BRIGHTSPACE:\n","\n"," * This notebook file \n"," * The answers to the questions in a separate PDF.\n"," \n","### During this practical session we will refresh the following topics:\n","\n"," * Basic image processing techniques (filtering, morphological operations, etc.)\n"," * Several types of image thresholing for object segmentation\n"," * Segmentation using the Region Growing method \n"]},{"cell_type":"code","execution_count":null,"id":"f8f8dcf7-faf8-44d6-a6ee-1a5e47046f76","metadata":{"id":"f8f8dcf7-faf8-44d6-a6ee-1a5e47046f76"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage.segmentation import flood_fill, flood\n","from skimage.morphology import disk, dilation, erosion, reconstruction\n","from skimage.filters import threshold_otsu, gaussian\n","from skimage.color import rgb2gray\n","from skimage.io import imread, imread_collection\n","\n","\n","# load the data D from the mri folder\n","!unzip mri.zip\n","D = imread_collection('mri/*')\n","\n","# plotting a few slices\n","\n","plt.rcParams['figure.figsize'] = [12, 8] # bump up the figure size a bit\n","fig, axs = plt.subplots(1,3)\n","axs[0].imshow(D[1], cmap='gray')\n","axs[0].set_title('Slice 2')\n","\n","axs[1].imshow(D[13], cmap='gray')\n","axs[1].set_title('Slice 14')\n","\n","axs[2].imshow(D[24], cmap='gray')\n","axs[2].set_title('Slice 25')\n","\n","plt.show()"]},{"cell_type":"markdown","id":"f713c1fa-c429-46f6-833d-0172429f0205","metadata":{"tags":["Question"],"id":"f713c1fa-c429-46f6-833d-0172429f0205"},"source":["## Question 1: \n","\n"," * What are the minimum and maximum intensity values in D?\n","\n"," * What is the type (uint8, unit16, boolean, double) of D? \n","\n"," * What are the minimum and maximum intensity values for this type of image?"]},{"cell_type":"code","execution_count":null,"id":"6a7629e0-189a-470d-8033-95c480a9a833","metadata":{"id":"6a7629e0-189a-470d-8033-95c480a9a833"},"outputs":[],"source":["# Effect of applying Gaussian filter with given sigma \n","\n","fig, axs = plt.subplots(1,3)\n","axs[0].imshow(gaussian(D[13], 2), cmap = 'gray')\n","axs[0].set_title('Slice 14, $\\sigma$ = 2')\n","\n","axs[1].imshow(gaussian(D[13], 5), cmap = 'gray')\n","axs[1].set_title('Slice 14, $\\sigma$ = 5')\n","\n","axs[2].imshow(gaussian(D[13], 10), cmap = 'gray')\n","axs[2].set_title('Slice 14, $\\sigma$ = 10')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"63580e56-ea9f-40ac-ace0-efb8f6075e20","metadata":{"id":"63580e56-ea9f-40ac-ace0-efb8f6075e20"},"outputs":[],"source":["# To plot the histogram of intensity values of the original image and the smoothed version.\n","# .ravel() is used to convert the 2d slice into a 1d array.\n","\n","fig, axs = plt.subplots(1,2)\n","axs[0].hist(D[13].ravel(), 40)\n","axs[0].set_title('Histogram of slice 14')\n","\n","axs[1].hist(gaussian(D[13], 5).ravel(), 40)\n","axs[1].set_title('Histogram of blurred slice 14')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"d0e255e3-f88a-4161-b6af-85dcf1bba057","metadata":{"id":"d0e255e3-f88a-4161-b6af-85dcf1bba057"},"outputs":[],"source":["# Normalize/scale the intensity values to [0, 1] range from [0, 255]. .concatenate is used to allow for\n","# arithmetic operations on the image collection\n","image = D.concatenate()/255;\n","\n","# The histograms can also be plotted as:\n","\n","image_14 = image[13]\n","image_14_gauss = gaussian(image[13], 5)\n","\n","fig, axs = plt.subplots(1,2)\n","axs[0].hist(image_14.ravel(), 40)\n","axs[0].set_title('Histogram of slice 14')\n","\n","axs[1].hist(image_14_gauss.ravel(), 40)\n","axs[1].set_title('Histogram of blurred slice 14')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"913295fa-6267-4ca1-b5ee-dc45b6314901","metadata":{"id":"913295fa-6267-4ca1-b5ee-dc45b6314901"},"outputs":[],"source":["# In this case, it is easier to get the \n","# actual numerical data for each bin, in this case 40 values. \n","# It is customary to assign values that won't be used to '_'\n","\n","h,_,__ = plt.hist(image_14.ravel(), 40)"]},{"cell_type":"code","execution_count":null,"id":"c112f39e","metadata":{"id":"c112f39e"},"outputs":[],"source":["# In order to create a mask that marks/masks some region of interest, \n","# a simple thresholding of a blurred image can be used. \n","# In this example, we are going to write our own\n","# code, which will be useful for many other exercises in this course. \n","\n","mask = np.zeros(image_14_gauss.shape)  # create all-zero-image of the same size\n","mask[image_14_gauss > 0.2] = 1\n","\n","fig, axs = plt.subplots(1,2)\n","axs[0].imshow(image_14_gauss, cmap = 'gray')\n","axs[0].set_title('Original Image')\n","\n","axs[1].imshow(mask, cmap = 'gray')\n","axs[1].set_title('Mask')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"efd89a2b","metadata":{"id":"efd89a2b"},"outputs":[],"source":["# Two other useful image processing operations come from the field of\n","# mathematical morphology: dilation and erosion. Both of them require a\n","# structuring element \n","\n","se = disk(1)\n","\n","mask_dil = dilation(mask, se)\n","mask_ero = erosion(mask, se)\n","\n","fig, axs = plt.subplots(1,3)\n","axs[0].imshow(mask, cmap='gray')\n","axs[0].set_title('Mask')\n","\n","axs[1].imshow(mask_dil, cmap='gray')\n","axs[1].set_title('Dilation')\n","\n","axs[2].imshow(mask_ero, cmap='gray')\n","axs[2].set_title('Erosion')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"8d36ae4f","metadata":{"id":"8d36ae4f"},"outputs":[],"source":["# We can use the morphological operations to find object/region boundaries, for\n","# example:\n","\n","fig, axs = plt.subplots(1,2)\n","axs[0].imshow(mask - mask_ero, cmap='gray')\n","axs[0].set_title('\"Inner\" boundary')\n","\n","axs[1].imshow(mask_dil - mask, cmap='gray')\n","axs[1].set_title('\"Outer\" boundary')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"4061e5d7","metadata":{"id":"4061e5d7"},"outputs":[],"source":["# We can also fill-in some parts of the image in a 'flood-fill' way,\n","# providing the starting point. The more advanced methods, e.g. region\n","# growing, will be considered later.\n","# The parameter 'connectivity' is set to 1 to avoid leakage over diagonally\n","# connected pixels\n","\n","fill_im = (mask - mask_ero)\n","\n","fig, axs = plt.subplots(1,2)\n","axs[0].imshow(flood_fill(fill_im, (3,3), 1, connectivity = 1), cmap = 'gray')\n","axs[0].set_title('Filling from (3, 3)')\n","\n","axs[1].imshow(flood_fill(fill_im, (80,85), 1, connectivity = 1), cmap='gray')\n","axs[1].set_title('Filling from (80, 85)')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"2763315b","metadata":{"id":"2763315b"},"outputs":[],"source":["# A useful function in this course is application of a user-specified \n","# lambda function to all the values in an array. Having that, we do\n","# not really need to use any 'for-loops'. Using the above mentioned function\n","# one can solve the majority, if not all exercises in this course. Note: all the \n","# exercises in this course can be solved without 'for-loops' which make the \n","# code more difficult to read and prone to errors. \n","# Syntax: (lambda x: 'function of x')(x)\n","# For example, to invert a uint8 image, we can just change all the\n","# intensity values according to the function y = 255 - x, \n","\n","fig, axs = plt.subplots(1,2)\n","\n","image_invert = (lambda x: 255 - x)(D[13])\n","# equivalent to image_invert = 255 - D[13]\n","\n","axs[0].imshow(image_invert, cmap = 'gray')\n","axs[0].set_title('Inverted with lambda function')\n","\n","# Lambda functions can also contain conditional statements (for example:(x > 3)).\n","# These will return 'True' or 'False' which can be converted to 1 or 0 by\n","# multiplying by 1. This can be used to avoid 'if-then' statements.\n","\n","axs[1].imshow((lambda x: (x > 80) * 1 + (x <= 80)*0)(D[13]), cmap='gray')\n","axs[1].set_title('Thresholded with lambda function')\n","\n","plt.show()"]},{"cell_type":"markdown","id":"c28f44d6","metadata":{"tags":["Exercise"],"id":"c28f44d6"},"source":["# Exercise 1.1: Thresholding\n"," \n"," * Randomly pick up a slice from D in the range of [0, 26]\n"," \n","\n"," * Compute the average intensity value, $\\mu$, for that slice and the standard deviation, $\\sigma$, excluding all the zero-valued pixels. \n"," \n","\n"," * Display the selected slice and another image in which all the values above $\\mu+\\sigma$ have values 1, all the pixels with intensities smaller than $\\mu - \\sigma$ have value 0, and inbetween - value 0.5. The computed $\\mu$ and $\\sigma$ should be displayed in the title. To display the numbers use an f-string:\n"," ```f\"Normal words {variable}\"```.\n"," \n","Note: numpy arrays remain linked, use .copy() to avoid changing the original array (f.e. ```slice_n = D[:,:,0,n].copy()```)."]},{"cell_type":"code","execution_count":null,"id":"a027457d","metadata":{"tags":["Answer_E"],"id":"a027457d"},"outputs":[],"source":["# Excercise 1.1 answer\n","\n"]},{"cell_type":"markdown","id":"45810623","metadata":{"tags":["Exercise"],"id":"45810623"},"source":["# Exercise 1.2: Brain segmentation\n","\n","In this exercise you will determine the fraction of gray matter, white\n","matter and CSF in a T1-weighted brain image. \n","\n"," * First, search for a skull-stripped T1-weighted axial brain image on Google. It is important that the skull is removed, otherwise the segmentation will become more complicated. \n"," \n","\n"," * Using thresholding, segment the image into gray matter, white matter and CSF and determine their relative fractions with respect to the total brain volume (i.e. the three segments together should sum up to 100%). \n"," \n","\n"," * Plot the three segments and put the relative fractions of these segments in the figure titles. \n"," \n"," \n"," Hint 1: to compute the area of a region/segment in a binary image use numpy's ```np.sum()```. \n"," \n"," Hint 2: If you want to use multiple thresholds at once, use the ```&``` sign: ```BW = (I < thresh1) & (I > thresh2) ```. "]},{"cell_type":"code","execution_count":null,"id":"cc9d1abd","metadata":{"tags":["Answer_E"],"id":"cc9d1abd"},"outputs":[],"source":["# Excercise 1.2 answer\n","\n"]},{"cell_type":"code","execution_count":null,"id":"2e46e921","metadata":{"id":"2e46e921"},"outputs":[],"source":["## Region Growing \n","\n","#  In this exercise we will use the flood fill function to segment the \n","#  brain ventricles on a Magnetic Resonance Image.\n"," \n","#  1) Load the brain.png file with the imread function as float data type.\n","\n","#  2) We transform our rgb image to grayscale with rgb2gray.\n","\n","#  3) Display the image.\n","\n","#  4) As we display the image we can select one pixel that represents the \n","#  area we want to segment(ventricles). Select one pixel on the left side.\n","\n","#  5) This pixel coordinates will represent the seed, which is the location \n","#  where the algorithm will start growing. The difference between a pixel's intensity \n","#  value and the region's mean, is used as a measure of similarity. The pixel\n","#  with the smallest difference measured this way is allocated to the respective region.\n","#  This process stops when the intensity difference between region mean and\n","#  new pixel become larger than a certain threshold. We will use 0.3\n","#\n","#  6) We Use the coordinates as input to the region growing function. \n"," \n","image = np.asarray(imread('brain.png'), dtype = float)\n","image = rgb2gray(image)\n","\n","image_left_highlighted = flood_fill(image, (124,120), 255, connectivity = 2, tolerance = 0.3*255)\n","\n","fig, axs = plt.subplots(1,3)\n","axs[0].imshow(image, cmap = 'gray')\n","axs[0].set_title(f\"Original Image\")\n","\n","axs[1].imshow(image_left_highlighted, cmap = 'gray')\n","axs[1].set_title(f\"Left Ventricle Highlighted\")\n","\n","# 9) We are interested in segmenting the right ventricle as well,\n","# so repeat the previous steps (5,7 and 8) using a coordinate from the right \n","# ventricle. Furthermore, save the result of the region growing algorithm  in  \n","# variable called |J2| and the addition result on a variable called |z2|.\n","\n","image_both_highlighted = flood_fill(image_left_highlighted, (124,135), 255, connectivity = 2, tolerance = 0.3*255)\n","\n","axs[2].imshow(image_both_highlighted, cmap = 'gray')\n","axs[2].set_title(f\"Both Ventricles Highlighted\")\n","\n","plt.show()"]},{"cell_type":"markdown","id":"8dbf070c","metadata":{"tags":["Question"],"id":"8dbf070c"},"source":["## Question 2: \n","\n","Explain why the region growing doesn't expand to the right ventricle.\n"]},{"cell_type":"markdown","id":"b4c16fef","metadata":{"tags":["Exercise"],"id":"b4c16fef"},"source":["# Exercise 1.3: Liver segmentation\n","\n"," Segment the liver from the abdomen-CT.jpg using the region growing algorithm.\n"," \n"," * After loading the image you will notice that is in rgb. Change it to gray-scale values using the rgb2gray function.\n"," \n","\n"," * Select a proper coordinate and threshold for the seed start growing.\n"," \n"," \n","Hint: the tolerance value is a number $< 25$, probably you will need to try\n"," several values.\n","\n","* It is possible that your mask of the liver will have many noise and artifacts, you can fix it using a proper morphological operation. \n","\n","Hint: the function 'flood' returns the filled region without the original image\n","\n","\n","* To show the overlay of your liver, add the liver mask to the gray-scale image.\n","\n","\n","* Plot in one figure the gray-scale image, the mask and the fusion of these two.\n","\n","\n","As you will find, a perfect segmentation of the liver is not possible with only regiongrowing.\n"]},{"cell_type":"code","execution_count":null,"id":"569f6807","metadata":{"tags":["Answer_E"],"id":"569f6807"},"outputs":[],"source":["# Excercise 1.3 answer\n","\n"]},{"cell_type":"markdown","id":"258f68c5","metadata":{"tags":["Question"],"id":"258f68c5"},"source":["## Question 3:\n","\n"," * According to the number of threshold/ seed coordinate values you had to try, can you mention one/two disadvantages of this segmentation method? \n","\n","\n"," * Can you also mention one/two advantages?\n","\n","\n"," * According to you, how this method  will perform  on organs with\n","     similar  structure that are  spacely close to each other? "]},{"cell_type":"markdown","id":"147fbec7","metadata":{"deletable":false,"editable":false,"tags":["Exercise"],"id":"147fbec7"},"source":["## Exercise 1.4: Metastases segmentation.\n","\n","The purpose of this exercise is to segment metastases in the liver and obtain the size of the largest metastasis. To this end, you will need to segment two structures: \n","\n","1) a segmentation the liver\n","\n","2) a segmentation of the metastases\n","\n"," * Load the image 'livermetastases.jpg'. Do not forget to convert it to a grayscale, double type.\n"," * Crop the image to the part $[200:399]; [200:399]$.\n"," * Make a mask for the liver, you can use tresholding and/or region growing\n"," * Make a mask for the metastases: use morphological operations to\n"," optimize the result. Note that there is not a single 'correct' solution, \n"," try to find a series of operations which gives you a good final\n"," segmentation. Create an image after every step and output the results as shown below. Please also \n"," explain why you decided to use these steps. \n"," * Determine the size of the largest metastasis. Assume the voxel size is $0.4*0.4*3$ mm$^3$"]},{"cell_type":"code","execution_count":null,"id":"40eecfd4","metadata":{"tags":["Answer_E"],"id":"40eecfd4"},"outputs":[],"source":["# Excercise 1.4 answer  \n","\n"]}],"metadata":{"celltoolbar":"Geen","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"},"latex_envs":{"LaTeX_envs_menu_present":true,"autoclose":false,"autocomplete":true,"bibliofile":"biblio.bib","cite_by":"apalike","current_citInitial":1,"eqLabelWithNumbers":true,"eqNumInitial":1,"hotkeys":{"equation":"Ctrl-E","itemize":"Ctrl-I"},"labels_anchors":false,"latex_user_defs":false,"report_style_numbering":false,"user_envs_cfg":false},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"toc-showcode":false,"toc-showmarkdowntxt":false,"toc-showtags":true,"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"AIP_segm1_Intro.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}